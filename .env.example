# Athena Recursive AI Configuration
# Copy this file to .env and configure your settings

# LM Studio Endpoints - Optimized for Balanced GPU Load
# GPU 1 (18GB): Orchestrator + Reasoning + Memory (logical/context-heavy)
# GPU 2 (9GB): Creative + Technical (creative/implementation tasks)
ORCHESTRATOR_URL=http://localhost:1234/v1
REASONING_EXPERT_URL=http://localhost:1235/v1
MEMORY_EXPERT_URL=http://localhost:1236/v1
CREATIVE_EXPERT_URL=http://localhost:1237/v1
TECHNICAL_EXPERT_URL=http://localhost:1238/v1

# Model Configuration
ORCHESTRATOR_MODEL=qwen2.5-14b-instruct
REASONING_MODEL=phi-3.5-mini-instruct
CREATIVE_MODEL=mistral-7b-instruct
TECHNICAL_MODEL=codeqwen-7b-instruct
MEMORY_MODEL=llama-3.1-8b-instruct

# GPU Configuration - Optimized Distribution for Maximum Throughput
# GPU 1 (0): Orchestrator (10GB) + Reasoning (3GB) + Memory (5GB) = ~18GB
# GPU 2 (1): Creative (4.5GB) + Technical (4.5GB) = ~9GB
ORCHESTRATOR_GPU=0
REASONING_GPU=0
MEMORY_GPU=0
CREATIVE_GPU=1
TECHNICAL_GPU=1

# System Configuration
MAX_CONTEXT_LENGTH=8192
TEMPERATURE=0.7
TOP_P=0.9
MAX_TOKENS=2048

# Logging
LOG_LEVEL=INFO
LOG_FILE=athena.log

# Global Workspace Theory Parameters
GWT_ATTENTION_THRESHOLD=0.6
GWT_WORKSPACE_SIZE=5
GWT_BROADCAST_DECAY=0.9

# Expert Routing
ENABLE_PARALLEL_CONSULTATION=true
CONFIDENCE_THRESHOLD=0.7
MAX_EXPERT_RETRIES=3
